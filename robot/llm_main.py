"""
LLM-Enhanced FastAPI server for MuJoCo robot simulation
Extends main.py with natural language control capabilities
"""

import queue
import threading
import uvicorn
from fastapi import FastAPI, Response, status
from fastapi.responses import JSONResponse, HTMLResponse
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
from simulator import MujocoSimulator
from llm_agent import LLMRobotAgent
import code_repository

# Load environment variables from .env file
load_dotenv()


# Server configuration
HOST = "0.0.0.0"
PORT = 8800  # Change to 8801 if port conflict
VERSION = "0.0.2-LLM"

# FastAPI application
app = FastAPI(
    title="LLM-Enabled MuJoCo Robot Simulator",
    description="Control Panda-Omron mobile robot via natural language (GPT-4)",
    version=VERSION
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Create simulator and LLM agent
simulator = MujocoSimulator()
code_repository.simulator = simulator
llm_agent = LLMRobotAgent()

# Action queue
actions_queue = queue.Queue()


def process_actions():
    """Process action queue in background thread."""
    print("Action processor started...")
    while True:
        try:
            action = actions_queue.get(timeout=0.1)
            action = action["action"]

            print(f"\n{'='*60}")
            print(f"Received Action:", action)

            if action["type"] == "run_code":
                code_str = action["payload"].get("code")
                try:
                    code_repository.exec_code(code_str)
                    print("Code execution completed successfully")
                except Exception as e:
                    print(f"\n[EXECUTION ERROR]")
                    print(f"  Type: {type(e).__name__}")
                    print(f"  Message: {e}")
                    import traceback
                    traceback.print_exc()
            print(f"{'='*60}\n")

            actions_queue.task_done()

        except queue.Empty:
            continue
        except Exception as e:
            print(f"Error processing action: {e}")
            import traceback
            traceback.print_exc()


def run_simulator():
    """Run MuJoCo simulator in background thread."""
    print("ğŸ¬ Simulator thread starting...")
    try:
        print("ğŸ¬ Calling simulator.run() - this will open MuJoCo viewer")
        simulator.run()
        print("ğŸ¬ simulator.run() returned (viewer closed)")
    except RuntimeError as e:
        if "mjpython" in str(e):
            print("\nâš ï¸  WARNING: MuJoCo viewer requires mjpython on macOS")
            print("   Simulator disabled - API server running without 3D viewer")
            print("   To enable viewer: run with 'mjpython llm_main.py'\n")
        else:
            print(f"\nâš ï¸  Simulator error: {e}\n")
    except Exception as e:
        print(f"\nâš ï¸  Simulator error: {e}\n")
        import traceback
        traceback.print_exc()


@app.get("/")
def read_root():
    """Get server info."""
    return {
        "name": "LLM-Enabled MuJoCo Robot Simulator",
        "version": VERSION,
        "status": "running",
        "features": ["natural_language_control", "gpt4_integration"]
    }


@app.post("/send_action")
def receive_action(action: dict):
    """
    Queue action for execution (original endpoint).

    Expected format:
        {
            "action": {
                "type": "run_code",
                "payload": {"code": "set_target_position(0, 0, PI)"}
            }
        }
    """
    if "action" in action and "type" in action["action"] and "payload" in action["action"]:
        actions_queue.put(action)
        return JSONResponse(
            status_code=status.HTTP_200_OK,
            content={"status": "success", "action_feedback": "good"}
        )
    return JSONResponse(
        status_code=status.HTTP_400_BAD_REQUEST,
        content={"status": "error", "message": "Invalid action format"}
    )


@app.post("/llm_command")
def llm_command(request: dict):
    """
    ğŸ¤– NEW: Natural language command endpoint (LLM-powered)

    Expected format:
        {
            "command": "ì •ì‚¬ê°í˜•ìœ¼ë¡œ ì›€ì§ì—¬ì¤˜",
            "execute": true  # Optional: auto-execute generated code
        }

    Returns:
        {
            "status": "success",
            "user_command": "...",
            "generated_code": "...",
            "executed": true/false
        }
    """
    try:
        user_command = request.get("command", "")
        auto_execute = request.get("execute", True)

        if not user_command:
            return JSONResponse(
                status_code=status.HTTP_400_BAD_REQUEST,
                content={"status": "error", "message": "No command provided"}
            )

        # LLMìœ¼ë¡œ ì½”ë“œ ìƒì„±
        print(f"\n{'='*60}")
        print(f"ğŸ¤– LLM Command: {user_command}")
        generated_code = llm_agent.generate_code(user_command)
        print(f"Generated Code:\n{generated_code}")
        print(f"{'='*60}\n")

        # ì—ëŸ¬ ì²´í¬
        if generated_code.startswith("# ERROR"):
            return JSONResponse(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                content={
                    "status": "error",
                    "user_command": user_command,
                    "error": generated_code
                }
            )

        # ìë™ ì‹¤í–‰ ì˜µì…˜
        executed = False
        if auto_execute:
            actions_queue.put({
                "action": {
                    "type": "run_code",
                    "payload": {"code": generated_code}
                }
            })
            executed = True

        return JSONResponse(
            status_code=status.HTTP_200_OK,
            content={
                "status": "success",
                "user_command": user_command,
                "generated_code": generated_code,
                "executed": executed
            }
        )

    except Exception as e:
        import traceback
        return JSONResponse(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            content={
                "status": "error",
                "message": str(e),
                "traceback": traceback.format_exc()
            }
        )


@app.get("/ui", response_class=HTMLResponse)
def get_ui():
    """Simple web UI for LLM robot control"""
    return """
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ğŸ¤– LLM Robot Control</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            padding: 40px;
        }
        h1 {
            color: #667eea;
            margin-bottom: 10px;
            font-size: 2.5em;
        }
        .subtitle {
            color: #666;
            margin-bottom: 30px;
            font-size: 1.1em;
        }
        .input-group {
            margin-bottom: 20px;
        }
        label {
            display: block;
            margin-bottom: 8px;
            font-weight: 600;
            color: #333;
        }
        input, textarea {
            width: 100%;
            padding: 12px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            font-size: 16px;
            transition: border-color 0.3s;
        }
        input:focus, textarea:focus {
            outline: none;
            border-color: #667eea;
        }
        button {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            padding: 15px 30px;
            border-radius: 8px;
            font-size: 18px;
            font-weight: 600;
            cursor: pointer;
            width: 100%;
            transition: transform 0.2s, box-shadow 0.2s;
        }
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(102, 126, 234, 0.4);
        }
        button:active {
            transform: translateY(0);
        }
        .examples {
            margin: 20px 0;
            padding: 15px;
            background: #f5f5f5;
            border-radius: 8px;
        }
        .example-btn {
            display: inline-block;
            margin: 5px;
            padding: 8px 15px;
            background: white;
            border: 1px solid #ddd;
            border-radius: 5px;
            cursor: pointer;
            font-size: 14px;
            transition: all 0.2s;
        }
        .example-btn:hover {
            background: #667eea;
            color: white;
            border-color: #667eea;
        }
        .response {
            margin-top: 20px;
            padding: 20px;
            background: #f9f9f9;
            border-radius: 8px;
            border-left: 4px solid #667eea;
        }
        pre {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 15px;
            border-radius: 8px;
            overflow-x: auto;
            margin-top: 10px;
        }
        .status {
            display: inline-block;
            padding: 5px 10px;
            border-radius: 5px;
            font-weight: 600;
            margin-bottom: 10px;
        }
        .status.success { background: #4caf50; color: white; }
        .status.error { background: #f44336; color: white; }
        .button-group {
            display: flex;
            gap: 10px;
            margin-top: 10px;
        }
        .voice-btn {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            flex: 1;
        }
        .voice-btn.listening {
            background: #ff4444;
            animation: pulse 1s infinite;
        }
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }
        .text-btn {
            flex: 2;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ¤– LLM Robot Control</h1>
        <p class="subtitle">ìì—°ì–´ë¡œ ë¡œë´‡ì„ ì œì–´í•˜ì„¸ìš” (Powered by GPT-4)</p>

        <div class="examples">
            <strong>ğŸ’¡ ì˜ˆì‹œ ëª…ë ¹ì–´:</strong><br>
            <span class="example-btn" onclick="setCommand('ì •ì‚¬ê°í˜•ìœ¼ë¡œ ì›€ì§ì—¬ì¤˜')">ì •ì‚¬ê°í˜• ì›€ì§ì´ê¸°</span>
            <span class="example-btn" onclick="setCommand('ì›í˜•ìœ¼ë¡œ ì²œì²œíˆ ëŒì•„ì¤˜')">ì›í˜• ê²½ë¡œ</span>
            <span class="example-btn" onclick="setCommand('ì‚¼ê°í˜• ê·¸ë ¤ì¤˜')">ì‚¼ê°í˜• ê·¸ë¦¬ê¸°</span>
            <span class="example-btn" onclick="setCommand('ì œìë¦¬ì—ì„œ í•œë°”í€´ íšŒì „')">ì œìë¦¬ íšŒì „</span>
            <span class="example-btn" onclick="setCommand('ì•ìœ¼ë¡œ 1ë¯¸í„° ì´ë™')">ì§ì„  ì´ë™</span>
        </div>

        <div class="input-group">
            <label for="command">ëª…ë ¹ì–´ ì…ë ¥:</label>
            <input type="text" id="command" placeholder="ì˜ˆ: ì •ì‚¬ê°í˜•ìœ¼ë¡œ ì›€ì§ì—¬ì¤˜" />
        </div>

        <div class="button-group">
            <button class="voice-btn" id="voiceBtn" onclick="startVoiceRecognition()">ğŸ¤ ìŒì„± ëª…ë ¹</button>
            <button class="text-btn" onclick="sendCommand()">ğŸš€ í…ìŠ¤íŠ¸ ì‹¤í–‰</button>
        </div>

        <div id="response" style="display:none;" class="response">
            <div id="status"></div>
            <div id="userCommand"></div>
            <strong>ìƒì„±ëœ ì½”ë“œ:</strong>
            <pre id="generatedCode"></pre>
        </div>
    </div>

    <script>
        // Web Speech API ì´ˆê¸°í™”
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition = null;
        let isListening = false;

        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.lang = 'ko-KR';
            recognition.continuous = false;
            recognition.interimResults = false;

            recognition.onstart = function() {
                isListening = true;
                const voiceBtn = document.getElementById('voiceBtn');
                voiceBtn.classList.add('listening');
                voiceBtn.textContent = 'ğŸ¤ ë“£ëŠ” ì¤‘...';
            };

            recognition.onresult = function(event) {
                const transcript = event.results[0][0].transcript;
                document.getElementById('command').value = transcript;
                // ìë™ìœ¼ë¡œ ëª…ë ¹ ì‹¤í–‰
                sendCommand();
            };

            recognition.onerror = function(event) {
                console.error('ìŒì„± ì¸ì‹ ì˜¤ë¥˜:', event.error);
                alert('ìŒì„± ì¸ì‹ ì˜¤ë¥˜: ' + event.error);
                resetVoiceButton();
            };

            recognition.onend = function() {
                resetVoiceButton();
            };
        }

        function resetVoiceButton() {
            isListening = false;
            const voiceBtn = document.getElementById('voiceBtn');
            voiceBtn.classList.remove('listening');
            voiceBtn.textContent = 'ğŸ¤ ìŒì„± ëª…ë ¹';
        }

        function startVoiceRecognition() {
            if (!recognition) {
                alert('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Chromeì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.');
                return;
            }

            if (isListening) {
                recognition.stop();
                return;
            }

            try {
                recognition.start();
            } catch (error) {
                console.error('ìŒì„± ì¸ì‹ ì‹œì‘ ì˜¤ë¥˜:', error);
                alert('ìŒì„± ì¸ì‹ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ' + error.message);
            }
        }

        function setCommand(cmd) {
            document.getElementById('command').value = cmd;
        }

        async function sendCommand() {
            const command = document.getElementById('command').value;
            if (!command.trim()) {
                alert('ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!');
                return;
            }

            const responseDiv = document.getElementById('response');
            const statusDiv = document.getElementById('status');
            const userCommandDiv = document.getElementById('userCommand');
            const codeDiv = document.getElementById('generatedCode');

            // Show loading
            responseDiv.style.display = 'block';
            statusDiv.innerHTML = '<span class="status">â³ ì²˜ë¦¬ ì¤‘...</span>';
            userCommandDiv.textContent = '';
            codeDiv.textContent = '';

            try {
                const response = await fetch('/llm_command', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ command: command, execute: true })
                });

                const data = await response.json();

                if (data.status === 'success') {
                    statusDiv.innerHTML = '<span class="status success">âœ… ì„±ê³µ!</span>';
                    userCommandDiv.innerHTML = `<strong>ëª…ë ¹ì–´:</strong> ${data.user_command}`;
                    codeDiv.textContent = data.generated_code;
                } else {
                    statusDiv.innerHTML = '<span class="status error">âŒ ì˜¤ë¥˜</span>';
                    userCommandDiv.innerHTML = `<strong>ì˜¤ë¥˜:</strong> ${data.message || data.error}`;
                }
            } catch (error) {
                statusDiv.innerHTML = '<span class="status error">âŒ ì—°ê²° ì˜¤ë¥˜</span>';
                userCommandDiv.innerHTML = `<strong>ì˜¤ë¥˜:</strong> ${error.message}`;
            }
        }

        // Enter í‚¤ë¡œ ì „ì†¡
        document.getElementById('command').addEventListener('keypress', function(e) {
            if (e.key === 'Enter') sendCommand();
        });
    </script>
</body>
</html>
    """


def main():
    """
    Start simulator, action processor, and FastAPI server.
    """
    # Start background threads
    print("ğŸ”§ Starting background threads...")
    sim_thread = threading.Thread(target=run_simulator, daemon=True)
    action_thread = threading.Thread(target=process_actions, daemon=True)
    
    sim_thread.start()
    action_thread.start()
    
    # Give threads time to initialize
    import time
    time.sleep(0.5)
    
    print("ğŸ”§ Threads started. Checking status...")
    print(f"   Simulator thread alive: {sim_thread.is_alive()}")
    print(f"   Action thread alive: {action_thread.is_alive()}")

    # Startup info
    print(f"\n{'='*60}")
    print(f"ğŸ¤– LLM-Enabled MuJoCo Robot Simulator")
    print(f"{'='*60}")
    print(f"Server: http://{HOST}:{PORT}")
    print(f"Web UI: http://{HOST}:{PORT}/ui")
    print(f"API docs: http://{HOST}:{PORT}/docs")
    print(f"{'='*60}\n")
    print(f"ğŸ’¡ Endpoints:")
    print(f"  POST /llm_command  - Natural language control (GPT-4)")
    print(f"  POST /send_action  - Direct code execution")
    print(f"  GET  /ui           - Web interface")
    print(f"{'='*60}\n")

    # Start server
    uvicorn.run(app, host=HOST, port=PORT, log_level="info")


if __name__ == "__main__":
    main()
